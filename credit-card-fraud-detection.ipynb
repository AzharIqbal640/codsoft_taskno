{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10619774,"sourceType":"datasetVersion","datasetId":6575337}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/credircard/creditcard.csv')\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.hist(bins=30,figsize=(12,10), grid=False )\nplt.suptitle('Histograms of Columns')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = df.Class.unique()\n\nsizes = df.Class.value_counts().values\n\nfig, ax = plt.subplots()\nax.pie(sizes, labels=labels, autopct='%1.3f%%')\nax.set_title('Target Variable Value Counts')\nplt.show()\nprint(df.Class.value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.boxenplot(data=df, x='Class', y='Amount')\nplt.title('Transaction Amount by Class ')\nplt.xlabel('Class')\nplt.ylabel('Transaction Amount')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.hist(df.Amount.values, 6, histtype='bar', facecolor='g')\nplt.show()\n\nprint(\"Minimum amount value is \", np.min(df.Amount.values))\nprint(\"Maximum amount value is \", np.max(df.Amount.values))\nprint(\"90% of the transactions have an amount less or equal than \", np.percentile(df.Amount.values, 90))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fraud = df[df['Class'] == 1]\nplt.scatter(fraud['Time'], fraud['Amount'], alpha=0.5)\nplt.title('Fraudulent Transactions Over Time')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Transaction Amount')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(data=df, x='Amount', hue='Class', bins=50)\nplt.title('Distribution of Transaction Amount by Class')\nplt.yscale('log')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Time distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x='Time', hue='Class', bins=50)\nplt.title('Distribution of Time by Class')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation matrix for important features\nplt.figure(figsize=(12, 8))\ncorrelation_matrix = df[['Amount', 'Time', 'Class'] + [f'V{i}' for i in range(1, 5)]].corr()\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\nplt.title('Correlation Matrix of Selected Features')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# standardize features \nfrom sklearn.preprocessing import StandardScaler\ndf.iloc[:, 1:30] = StandardScaler().fit_transform(df.iloc[:, 1:30])\ndata_matrix = df.values\n\n# Separate features and target\nX = data_matrix[:, 1:30]\ny = data_matrix[:, 30]\n\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\nprint(\"Original training set shape:\", dict(zip(*np.unique(y_train, return_counts=True))))\nprint('\\n')\nprint('X.shape=', X.shape, 'y.shape=', y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('X_train.shape=', X_train.shape, 'Y_train.shape=', y_train.shape)\nprint('X_test.shape=', X_test.shape, 'Y_test.shape=', y_test.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DecisionTreeClassifier model\ndt_model = DecisionTreeClassifier(max_depth=4, random_state=42)\n\n# Train the model\ndt_model.fit(X_train, y_train)\n\n# Make predictions\ny_pred = dt_model.predict(X_test)\n\n# Evaluate the accuracy\naccuracy = dt_model.score(X_test, y_test)\nprint(\"DecisionTreeClassifier Accuracy: {0:.5f}\".format(accuracy))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Generate the confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Plot the confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix for Decision Tree Classifier')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_model.fit(X_train, y_train)\n\n# Make predictions\ny_pred_rf = rf_model.predict(X_test)\n\n# Evaluate the accuracy\naccuracy_rf = rf_model.score(X_test, y_test)\nprint(\"RandomForestClassifier Accuracy: {0:.5f}\".format(accuracy_rf))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svm_model = SVC(C=1.0, random_state=42)  # dual=False für große Datensätze empfohlen\nsvm_model.fit(X_train, y_train)\ny_pred_svm = svm_model.predict(X_test)\naccuracy_svm = svm_model.score(X_test, y_test)\n\nprint(\"SVC Accuracy: {0:.5f}\".format(accuracy_svm))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matrix_dt = confusion_matrix(y_test, y_pred_svm)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap='Blues', xticklabels=['Legitimate', 'Fraudulent'], yticklabels=['Legitimate', 'Fraudulent'])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('SVM Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n\n# Train the model\nlogreg_model.fit(X_train, y_train)\n\n# Make predictions\ny_pred_logreg = logreg_model.predict(X_test)\n\n# Evaluate the accuracy\naccuracy_logreg = logreg_model.score(X_test, y_test)\nprint(\"LogisticRegression Accuracy: {0:.5f}\".format(accuracy_logreg))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_names = ['Decision Tree', 'SVM', 'Random Forest', 'Logistic Regression']\naccuracies = [accuracy, accuracy_svm, accuracy_rf, accuracy_logreg]\n\n# Plotting the accuracies\nplt.figure(figsize=(10, 6))\nplt.bar(model_names, accuracies, color=['blue', 'green', 'red', 'purple'])\nplt.xlabel('Model')\nplt.ylabel('Accuracy')\nplt.title('Accuracy of Different Models')\nplt.ylim(0.99, 1.0)  # Adjust the y-axis to better visualize the differences\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_importance = pd.DataFrame({\n    'feature': df.columns[1:30],  # Exclude 'Time' and 'Class' columns\n    'importance': rf_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(12, 6))\nsns.barplot(data=feature_importance.head(10), x='importance', y='feature')\nplt.title('Top 10 Most Important Features')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate classification reports for each model\nreport_dt = classification_report(y_test, y_pred, target_names=['Legitimate', 'Fraudulent'])\nreport_svm = classification_report(y_test, y_pred_svm, target_names=['Legitimate', 'Fraudulent'])\nreport_rf = classification_report(y_test, y_pred_rf, target_names=['Legitimate', 'Fraudulent'])\nreport_logreg = classification_report(y_test, y_pred_logreg, target_names=['Legitimate', 'Fraudulent'])\n\n# Print the reports\nprint(\"Decision Tree Classifier Report:\\n\", report_dt)\nprint(\"SVM Classifier Report:\\n\", report_svm)\nprint(\"Random Forest Classifier Report:\\n\", report_rf)\nprint(\"Logistic Regression Classifier Report:\\n\", report_logreg)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}